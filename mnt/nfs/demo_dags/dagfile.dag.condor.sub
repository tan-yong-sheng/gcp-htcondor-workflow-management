# Filename: dagfile.dag.condor.sub
# Generated by condor_submit_dag dagfile.dag 
universe    = scheduler
executable  = /usr/bin/condor_dagman
getenv      = CONDOR_CONFIG,_CONDOR_*,PATH,PYTHONPATH,PERL*,PEGASUS_*,TZ,HOME,USER,LANG,LC_ALL,BEARER_TOKEN,BEARER_TOKEN_FILE,XDG_RUNTIME_DIR
output      = dagfile.dag.lib.out
error       = dagfile.dag.lib.err
log         = dagfile.dag.dagman.log
remove_kill_sig = SIGUSR1
My.OtherJobRemoveRequirements = "DAGManJobId =?= $(cluster)"
# Note: default on_exit_remove expression:
# (ExitSignal =?= 11 || (ExitCode =!= UNDEFINED && ExitCode >=0 && ExitCode <= 2))
# attempts to ensure that DAGMan is automatically
# requeued by the schedd if it exits abnormally or
# is killed (e.g., during a reboot).
on_exit_remove = (ExitSignal =?= 11 || (ExitCode =!= UNDEFINED && ExitCode >=0 && ExitCode <= 2))
copy_to_spool = False
arguments = "-p 0 -f -l . -Lockfile dagfile.dag.lock -Dag dagfile.dag -MaxIdle 1000 -CsdVersion $CondorVersion:' '23.10.19' '2025-01-03' 'BuildID:' '777890' 'PackageID:' '23.10.19-1+ubu22' 'GitSHA:' '91176a00' '$ -dagman /usr/bin/condor_dagman -AutoRescue 1 -DoRescueFrom 0"
environment = "_CONDOR_DAGMAN_LOG=dagfile.dag.dagman.out _CONDOR_MAX_DAGMAN_LOG=0 _CONDOR_SCHEDD_ADDRESS_FILE=/var/spool/condor/.schedd_address _CONDOR_SCHEDD_DAEMON_AD_FILE=/var/spool/condor/.schedd_classad"
queue
